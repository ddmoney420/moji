---
type: code
status: completed
labels:
- performance
- testing
target_files:
- internal/figlet/figlet_bench_test.go
- internal/convert/convert_bench_test.go
- internal/dither/dither_bench_test.go
- internal/filters/filters_bench_test.go
- internal/effects/effects_bench_test.go
model: claude-haiku-4-5-20251001
---
# Add Performance Benchmarks for Core Operations

## Problem Description

The moji codebase lacks benchmark tests to track performance over time. Without benchmarks, performance regressions can go unnoticed and optimization efforts cannot be measured. Key operations that need benchmarking include font parsing, image conversion, dithering, filters, and text effects.

## Solution Approach

Add `*_bench_test.go` files to core packages with comprehensive benchmarks:

1. `internal/figlet/` - Font parsing and text rendering
2. `internal/convert/` - Image to ASCII conversion
3. `internal/dither/` - All dithering algorithms
4. `internal/filters/` - Image filter application
5. `internal/effects/` - Text effect transformations

## Acceptance Criteria

- [x] `figlet_bench_test.go` with font parsing and render benchmarks
- [x] `convert_bench_test.go` with image conversion benchmarks (various sizes)
- [x] `dither_bench_test.go` with all algorithm benchmarks
- [x] `filters_bench_test.go` with filter application benchmarks
- [x] `effects_bench_test.go` with text transformation benchmarks
- [x] Each benchmark uses `b.ReportAllocs()` for memory tracking
- [x] Benchmarks use realistic data sizes (small/medium/large)
- [x] Sub-benchmarks for variations (e.g., `b.Run("100x100", ...)`)
- [x] All benchmarks run without errors
- [x] Document baseline results in comments
- [x] go vet passes with no errors

## Technical Notes

- Use `testing.B` with proper reset patterns
- Create test fixtures once in `func init()` or `TestMain`
- Include memory allocation benchmarks
- Target operations: parse, render, convert, dither, filter, effect